{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Express sklearn pipeline as codeflare pipeline\n",
    "Reference: https://scikit-learn.org/stable/auto_examples/semi_supervised/plot_semi_supervised_newsgroups.html#sphx-glr-auto-examples-semi-supervised-plot-semi-supervised-newsgroups-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Semi-supervised Classification on a Text Dataset\n",
    "\n",
    "In this example, semi-supervised classifiers are trained on the 20 newsgroups\n",
    "dataset (which will be automatically downloaded).\n",
    "\n",
    "You can adjust the number of categories by giving their names to the dataset\n",
    "loader or setting them to `None` to get all 20 of them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents\n",
      "20 categories\n",
      "\n",
      "Supervised SGDClassifier on 100% of the data:\n",
      "Number of training samples: 8485\n",
      "Unlabeled samples in training set: 0\n",
      "Micro-averaged F1 score on test set: 0.901\n",
      "----------\n",
      "\n",
      "Supervised SGDClassifier on 20% of the training data:\n",
      "Number of training samples: 1692\n",
      "Unlabeled samples in training set: 0\n",
      "Micro-averaged F1 score on test set: 0.786\n",
      "----------\n",
      "\n",
      "SelfTrainingClassifier on 20% of the training data (rest is unlabeled):\n",
      "Number of training samples: 8485\n",
      "Unlabeled samples in training set: 6793\n",
      "End of iteration 1, added 2875 new labels.\n",
      "End of iteration 2, added 681 new labels.\n",
      "End of iteration 3, added 234 new labels.\n",
      "End of iteration 4, added 84 new labels.\n",
      "End of iteration 5, added 29 new labels.\n",
      "End of iteration 6, added 11 new labels.\n",
      "End of iteration 7, added 9 new labels.\n",
      "End of iteration 8, added 2 new labels.\n",
      "End of iteration 9, added 4 new labels.\n",
      "End of iteration 10, added 7 new labels.\n",
      "Micro-averaged F1 score on test set: 0.834\n",
      "----------\n",
      "\n",
      "LabelSpreading on 20% of the data (rest is unlabeled):\n",
      "Number of training samples: 8485\n",
      "Unlabeled samples in training set: 6793\n",
      "Micro-averaged F1 score on test set: 0.652\n",
      "----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "data = fetch_20newsgroups(subset='train', categories=None)\n",
    "print(\"%d documents\" % len(data.filenames))\n",
    "print(\"%d categories\" % len(data.target_names))\n",
    "print()\n",
    "\n",
    "# Parameters\n",
    "sdg_params = dict(alpha=1e-5, penalty='l2', loss='log')\n",
    "vectorizer_params = dict(ngram_range=(1, 2), min_df=5, max_df=0.8)\n",
    "\n",
    "# Supervised Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(**vectorizer_params)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(**sdg_params)),\n",
    "])\n",
    "# SelfTraining Pipeline\n",
    "st_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(**vectorizer_params)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SelfTrainingClassifier(SGDClassifier(**sdg_params), verbose=True)),\n",
    "])\n",
    "# LabelSpreading Pipeline\n",
    "ls_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(**vectorizer_params)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    # LabelSpreading does not support dense matrices\n",
    "    ('todense', FunctionTransformer(lambda x: x.todense())),\n",
    "    ('clf', LabelSpreading()),\n",
    "])\n",
    "\n",
    "\n",
    "def eval_and_print_metrics(clf, X_train, y_train, X_test, y_test):\n",
    "    print(\"Number of training samples:\", len(X_train))\n",
    "    print(\"Unlabeled samples in training set:\",\n",
    "          sum(1 for x in y_train if x == -1))\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Micro-averaged F1 score on test set: \"\n",
    "          \"%0.3f\" % f1_score(y_test, y_pred, average='micro'))\n",
    "    print(\"-\" * 10)\n",
    "    print()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X, y = data.data, data.target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    print(\"Supervised SGDClassifier on 100% of the data:\")\n",
    "    eval_and_print_metrics(pipeline, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # select a mask of 20% of the train dataset\n",
    "    y_mask = np.random.rand(len(y_train)) < 0.2\n",
    "\n",
    "    # X_20 and y_20 are the subset of the train dataset indicated by the mask\n",
    "    X_20, y_20 = map(list, zip(*((x, y)\n",
    "                     for x, y, m in zip(X_train, y_train, y_mask) if m)))\n",
    "    print(\"Supervised SGDClassifier on 20% of the training data:\")\n",
    "    eval_and_print_metrics(pipeline, X_20, y_20, X_test, y_test)\n",
    "\n",
    "    # set the non-masked subset to be unlabeled\n",
    "    y_train[~y_mask] = -1\n",
    "    print(\"SelfTrainingClassifier on 20% of the training data (rest \"\n",
    "          \"is unlabeled):\")\n",
    "    eval_and_print_metrics(st_pipeline, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    if 'CI' not in os.environ:\n",
    "        # LabelSpreading takes too long to run in the online documentation\n",
    "        print(\"LabelSpreading on 20% of the data (rest is unlabeled):\")\n",
    "        eval_and_print_metrics(ls_pipeline, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents\n",
      "20 categories\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-01 10:55:34,397\tINFO services.py:1267 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised SGDClassifier on 100% of the data:\n",
      "Number of training samples: 8485\n",
      "Unlabeled samples in training set: 0\n"
     ]
    },
    {
     "ename": "RayTaskError(ValueError)",
     "evalue": "\u001b[36mray::execute_or_node_remote()\u001b[39m (pid=5002, ip=192.168.1.230)\n  File \"python/ray/_raylet.pyx\", line 505, in ray._raylet.execute_task\n  File \"/Users/yuanchi/anaconda3/lib/python3.8/site-packages/codeflare_pipelines-1.0.0-py3.8.egg/codeflare/pipelines/Runtime.py\", line 43, in execute_or_node_remote\n  File \"/Users/yuanchi/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 702, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"/Users/yuanchi/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\", line 1477, in transform\n    X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy)\n  File \"/Users/yuanchi/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/Users/yuanchi/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 593, in check_array\n    array = _ensure_sparse_format(array, accept_sparse=accept_sparse,\n  File \"/Users/yuanchi/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 381, in _ensure_sparse_format\n    spmatrix = spmatrix.astype(dtype)\n  File \"/Users/yuanchi/anaconda3/lib/python3.8/site-packages/scipy/sparse/data.py\", line 72, in astype\n    self._deduped_data().astype(dtype, casting=casting, copy=copy),\n  File \"/Users/yuanchi/anaconda3/lib/python3.8/site-packages/scipy/sparse/data.py\", line 32, in _deduped_data\n    self.sum_duplicates()\n  File \"/Users/yuanchi/anaconda3/lib/python3.8/site-packages/scipy/sparse/compressed.py\", line 1098, in sum_duplicates\n    self.sort_indices()\n  File \"/Users/yuanchi/anaconda3/lib/python3.8/site-packages/scipy/sparse/compressed.py\", line 1144, in sort_indices\n    _sparsetools.csr_sort_indices(len(self.indptr) - 1, self.indptr,\nValueError: WRITEBACKIFCOPY base is read-only",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError(ValueError)\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3afb1332e047>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Supervised SGDClassifier on 100% of the data:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0meval_and_print_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_clf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m# select a mask of 20% of the train dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-3afb1332e047>\u001b[0m in \u001b[0;36meval_and_print_metrics\u001b[0;34m(clf, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# execute FIT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mpipeline_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExecutionType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# select a pipeline referenced by clf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/codeflare_pipelines-1.0.0-py3.8.egg/codeflare/pipelines/Runtime.py\u001b[0m in \u001b[0;36mexecute_pipeline\u001b[0;34m(pipeline, mode, pipeline_input)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mpost_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_post_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_node_input_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNodeInputType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                 \u001b[0mexecute_or_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_node_input_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNodeInputType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAND\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mexecute_and_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_edges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/codeflare_pipelines-1.0.0-py3.8.egg/codeflare/pipelines/Runtime.py\u001b[0m in \u001b[0;36mexecute_or_node\u001b[0;34m(node, pre_edges, edge_args, post_edges, mode)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mexec_xyrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mxy_ref_ptr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mXyref_ptrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mxy_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy_ref_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0minner_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute_or_node_remote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxy_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mexec_xyrefs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclient_mode_should_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   1479\u001b[0m                     \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_object_store_memory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRayTaskError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1481\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_instanceof_cause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1482\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRayTaskError(ValueError)\u001b[0m: \u001b[36mray::execute_or_node_remote()\u001b[39m (pid=5002, ip=192.168.1.230)\n  File \"python/ray/_raylet.pyx\", line 505, in ray._raylet.execute_task\n  File \"/Users/yuanchi/anaconda3/lib/python3.8/site-packages/codeflare_pipelines-1.0.0-py3.8.egg/codeflare/pipelines/Runtime.py\", line 43, in execute_or_node_remote\n  File \"/Users/yuanchi/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 702, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"/Users/yuanchi/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\", line 1477, in transform\n    X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy)\n  File \"/Users/yuanchi/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/Users/yuanchi/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 593, in check_array\n    array = _ensure_sparse_format(array, accept_sparse=accept_sparse,\n  File \"/Users/yuanchi/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 381, in _ensure_sparse_format\n    spmatrix = spmatrix.astype(dtype)\n  File \"/Users/yuanchi/anaconda3/lib/python3.8/site-packages/scipy/sparse/data.py\", line 72, in astype\n    self._deduped_data().astype(dtype, casting=casting, copy=copy),\n  File \"/Users/yuanchi/anaconda3/lib/python3.8/site-packages/scipy/sparse/data.py\", line 32, in _deduped_data\n    self.sum_duplicates()\n  File \"/Users/yuanchi/anaconda3/lib/python3.8/site-packages/scipy/sparse/compressed.py\", line 1098, in sum_duplicates\n    self.sort_indices()\n  File \"/Users/yuanchi/anaconda3/lib/python3.8/site-packages/scipy/sparse/compressed.py\", line 1144, in sort_indices\n    _sparsetools.csr_sort_indices(len(self.indptr) - 1, self.indptr,\nValueError: WRITEBACKIFCOPY base is read-only"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import codeflare.pipelines.Datamodel as dm\n",
    "import codeflare.pipelines.Runtime as rt\n",
    "from codeflare.pipelines.Datamodel import Xy\n",
    "from codeflare.pipelines.Datamodel import XYRef\n",
    "from codeflare.pipelines.Runtime import ExecutionType\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "data = fetch_20newsgroups(subset='train', categories=None)\n",
    "print(\"%d documents\" % len(data.filenames))\n",
    "print(\"%d categories\" % len(data.target_names))\n",
    "print()\n",
    "\n",
    "# Parameters\n",
    "sdg_params = dict(alpha=1e-5, penalty='l2', loss='log')\n",
    "vectorizer_params = dict(ngram_range=(1, 2), min_df=5, max_df=0.8)\n",
    "\n",
    "# Supervised Pipeline\n",
    "pipeline = dm.Pipeline()\n",
    "\n",
    "vect = CountVectorizer(**vectorizer_params)\n",
    "tfidf = TfidfTransformer()\n",
    "clf1 = SGDClassifier(**sdg_params)\n",
    "clf2 = SelfTrainingClassifier(SGDClassifier(**sdg_params), verbose=True)\n",
    "todense = FunctionTransformer(lambda x: x.todense())\n",
    "clf3 = LabelSpreading() \n",
    "\n",
    "node_vect = dm.EstimatorNode('vect', CountVectorizer(**vectorizer_params))\n",
    "node_tfidf = dm.EstimatorNode('tfidf', TfidfTransformer())\n",
    "node_clf1 = dm.EstimatorNode('clf1', SGDClassifier(**sdg_params))\n",
    "node_clf2 = dm.EstimatorNode('clf2', SelfTrainingClassifier(SGDClassifier(**sdg_params), verbose=True))\n",
    "node_todense = dm.EstimatorNode('todense', FunctionTransformer(lambda x: x.todense()))\n",
    "node_clf3 = dm.EstimatorNode('clf3', LabelSpreading())\n",
    "\n",
    "pipeline.add_edge(node_vect, node_tfidf)\n",
    "# Supervised Pipeline\n",
    "pipeline.add_edge(node_tfidf, node_clf1)\n",
    "# SelfTraining Pipeline\n",
    "pipeline.add_edge(node_tfidf, node_clf2)\n",
    "# LabelSpreading Pipeline\n",
    "pipeline.add_edge(node_tfidf, node_todense)\n",
    "pipeline.add_edge(node_todense, node_clf3)\n",
    "\n",
    "\n",
    "def eval_and_print_metrics(clf, X_train, y_train, X_test, y_test):\n",
    "    print(\"Number of training samples:\", len(X_train))\n",
    "    print(\"Unlabeled samples in training set:\",\n",
    "          sum(1 for x in y_train if x == -1))\n",
    "    \n",
    "    pipeline_input = dm.PipelineInput()\n",
    "    pipeline_input.add_xy_arg(node_vect, dm.Xy(X_train, y_train))\n",
    "    \n",
    "    # execute FIT\n",
    "    pipeline_output = rt.execute_pipeline(pipeline, ExecutionType.FIT, pipeline_input)\n",
    "    \n",
    "    # select a pipeline referenced by clf\n",
    "    selected_pipeline = rt.select_pipeline(pipeline_output, clf[0])\n",
    "    \n",
    "    # execute PREDICT\n",
    "    pipeline_input = dm.PipelineInput()\n",
    "    pipeline_input.add_xy_arg(node_vect, dm.Xy(X_test, y_test))\n",
    "    predict_output = rt.execute_pipeline(selected_pipeline, ExecutionType.PREDICT, pipeline_input)\n",
    "    \n",
    "    predict_clf_output = predict_output.get_xyrefs(clf)\n",
    "    y_pred = ray.get(predict_clf_output[0].get_yref())\n",
    "    \n",
    "    print(\"Micro-averaged F1 score on test set: \"\n",
    "          \"%0.3f\" % f1_score(y_test, y_pred, average='micro'))\n",
    "    print(\"-\" * 10)\n",
    "    print()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    ray.shutdown()\n",
    "    ray.init()\n",
    "    \n",
    "    X, y = data.data, data.target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    print(\"Supervised SGDClassifier on 100% of the data:\")\n",
    "    eval_and_print_metrics(node_clf1, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # select a mask of 20% of the train dataset\n",
    "    y_mask = np.random.rand(len(y_train)) < 0.2\n",
    "\n",
    "    # X_20 and y_20 are the subset of the train dataset indicated by the mask\n",
    "    X_20, y_20 = map(list, zip(*((x, y)\n",
    "                     for x, y, m in zip(X_train, y_train, y_mask) if m)))\n",
    "    print(\"Supervised SGDClassifier on 20% of the training data:\")\n",
    "    eval_and_print_metrics(node_clf1, X_20, y_20, X_test, y_test)\n",
    "\n",
    "    # set the non-masked subset to be unlabeled\n",
    "    y_train[~y_mask] = -1\n",
    "    print(\"SelfTrainingClassifier on 20% of the training data (rest \"\n",
    "          \"is unlabeled):\")\n",
    "    eval_and_print_metrics(node_clf2, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    if 'CI' not in os.environ:\n",
    "        # LabelSpreading takes too long to run in the online documentation\n",
    "        print(\"LabelSpreading on 20% of the data (rest is unlabeled):\")\n",
    "        eval_and_print_metrics(node_clf3, X_train, y_train, X_test, y_test)\n",
    "        \n",
    "    ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
